{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmokeyNet Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Summary:</b><br>\n",
    "The SmokeyNet data used was generated and prepared by the San Diego Supercomputer Center and was manually provided in json format. The data is image predictions for the [FIgLib dataset](http://hpwren.ucsd.edu/HPWREN-FIgLib/HPWREN-FIgLib-Data/). The data consists of both whole image predictions and image tile predictions, and also contains the actual groundtruth value. The data provided was originally split into 3 files: train, validation, and test. This notebook reads in the 3 files, and combines them into a single file with a new column added for the file source (train, valid, test).\n",
    "\n",
    "- Read in 3 smokeynet files\n",
    "- Join into single dataset with new column to retain the source (train, valid, test)\n",
    "- Write new dataset to csv\n",
    "\n",
    "<b>Output:</b><br>\n",
    ".<br>\n",
    "└──data<br>\n",
    "&emsp;&emsp;&emsp;└── processed<br>\n",
    "&emsp;&emsp;&emsp;&nbsp;&nbsp;&emsp;&emsp;&nbsp;└── smokeynet.csv<br>\n",
    "\n",
    "<b>Areas for Improvement:</b><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smokeynet_parse(data_df):\n",
    "    \"\"\"\n",
    "    Extract date, year and adds them as columns to the dataframe for aggregation.\n",
    "    \"\"\"\n",
    "    # tranpose the data\n",
    "    data_df_T = data_df.transpose().reset_index().rename(columns={\"index\": \"filepath\"})\n",
    "\n",
    "    # camera name is actuall event name\n",
    "    data_df_T = data_df_T.rename(columns={\"camera_name\": \"event_name\"})\n",
    "\n",
    "    # extract values\n",
    "    event_split_df = data_df_T[\"event_name\"].str.split(\"_\", n=2, expand=True)\n",
    "    data_df_T[\"camera_name\"] = event_split_df[2]\n",
    "    data_df_T[\"date\"] = event_split_df[0]\n",
    "    data_df_T[\"year\"] = data_df_T[\"date\"].str[:4]\n",
    "    # data_df_T[\"img_seq\"] = data_df_T[\"filepath\"].str.split(\"_\", expand=True)[3]\n",
    "\n",
    "    return data_df_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data + explore event counts by year across 3 json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016    12\n",
       "2017    38\n",
       "2018    53\n",
       "2019    29\n",
       "2020    11\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df = pd.read_json(\"../../data/raw/smokeynet_train.json\")\n",
    "train_data_df = smokeynet_parse(train_data_df)\n",
    "# camera_name is actually event_name\n",
    "train_data_df[[\"event_name\", \"year\"]].drop_duplicates()[\n",
    "    \"year\"\n",
    "].value_counts().sort_index()\n",
    "# unique fire events - 143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018     6\n",
       "2019    29\n",
       "2020    27\n",
       "2021     2\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_df = pd.read_json(\"../../data/raw/smokeynet_valid.json\")\n",
    "valid_data_df = smokeynet_parse(valid_data_df)\n",
    "# camera_name is actually event_name\n",
    "valid_data_df[[\"event_name\", \"year\"]].drop_duplicates()[\n",
    "    \"year\"\n",
    "].value_counts().sort_index()\n",
    "# unique fire events - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016     2\n",
       "2017     1\n",
       "2018     4\n",
       "2019    21\n",
       "2020    29\n",
       "2021     6\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df = pd.read_json(\"../../data/raw/smokeynet_test.json\")\n",
    "test_data_df = smokeynet_parse(test_data_df)\n",
    "# camera_name is actually event_name\n",
    "test_data_df[[\"event_name\", \"year\"]].drop_duplicates()[\n",
    "    \"year\"\n",
    "].value_counts().sort_index()\n",
    "# unique fire events - 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat + write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df[\"file_source\"] = \"train\"  # 10438 rows\n",
    "valid_data_df[\"file_source\"] = \"valid\"  # 4911 rows\n",
    "test_data_df[\"file_source\"] = \"test\"  # 4885 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_smokeynet_data_df = pd.concat(\n",
    "    [train_data_df, valid_data_df, test_data_df]\n",
    ")  # 20234 rows\n",
    "# all_smokeynet_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_smokeynet_data_df.to_csv(\"../../data/processed/smokeynet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e2bfeb5113bf25857e2973a76cfe44336c562d23ec8db64184452b7fc34d49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
